{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping with Selenium\n",
    "\n",
    "Web scrapping is a simple way to get images (or other kind of data) from the web. With Selenium library we can perform the web scraping with few command lines.\n",
    "\n",
    "### Download ChromeDriver\n",
    "To scrap images from the web, it's recommended to use ChromeDriver (or other navigator), to download it, [click here](https://chromedriver.chromium.org/).\n",
    "\n",
    "For this example, we'll scrap images from Facebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "import wget\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Log into a Facebook account\n",
    "\n",
    "When we're confronted with a web scrapping task, we must know the website, it means, know how to navigate in this page, know where there's notifications. If  log-in is required, we must have access to developer mode, to ensure where the XPATH is located in the website, for example. For these reasons, we utilize the ChromeDriver. The first steps to scrap images from Facebook are:\n",
    "\n",
    "- Define the web driver\n",
    "- Disable the notification\n",
    "- Set the path location of your navigator\n",
    "- Set the path to have access to the ChromerDiver\n",
    "- Get the web page to scrap the data\n",
    "- Get in the web page the path for all elements that are clickable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = webdriver.ChromeOptions()\n",
    "prefs = {\"profile.default_content_setting_values.notifications\" : 2} # to disable the notification\n",
    "chrome_options.add_experimental_option(\"prefs\",prefs)\n",
    "chrome_options.binary_location = '/usr/bin/google-chrome'\n",
    "driver = webdriver.Chrome('/path/to/chromedriver', chrome_options=chrome_options)\n",
    "\n",
    "driver.get(\"https://www.facebook.com\") # to open the web page\n",
    "\n",
    "# To pass through the mensage \"Accept cookies from Facebook on this browser?\"\n",
    "WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, \"/html/body/div[3]/div[2]/div/div/div/div/div[3]/button[2]\"))).click()\n",
    "\n",
    "# To get the log-in elements\n",
    "username = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"input[name='email']\")))\n",
    "password = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"input[name='pass']\")))\n",
    "\n",
    "# Log-in\n",
    "username.clear()\n",
    "username.send_keys(\"xxxxx@xxx.xxx\")\n",
    "password.clear()\n",
    "password.send_keys(\"****\")\n",
    "\n",
    "# To pass through the mensage to save the email and password\n",
    "WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, \"/html/body/div[1]/div[2]/div[1]/div/div/div/div[2]/div/div[1]/form/div[2]/button\"))).click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Extracting the images from a Facebook page\n",
    "\n",
    "Once we've connected into the Facebook, there are some steps to scrap images from a specific Facebook page\n",
    "\n",
    "- Create an empty list to store the links\n",
    "- Open the target page on Facebook\n",
    "- Main loop to scroll down in the page (Facebook loads your pages dynamically)\n",
    "- Create an anchors list using the attribute find_elements_by_tag_name('a'), this is a particularity of Facebook page\n",
    "- List comprehension to get all possibles links\n",
    "- Another list comprehension to get the photos links\n",
    "- A loop inside the anchors list to open each link (open the photo page, find the image, append the image link into the image list)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wait 5 seconds to allow your new page to load\n",
    "time.sleep(5)\n",
    "images = []\n",
    "\n",
    "driver.get(\"https://www.facebook.com/page/photos\")\n",
    "time.sleep(10) # waiting to load the page\n",
    "    \n",
    "# scrolling 500 times, the total amount of photos will depend on the connection    \n",
    "for i in range(0, 500):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    #target all the link elements on the page\n",
    "    anchors = driver.find_elements_by_tag_name('a')\n",
    "    anchors = [a.get_attribute('href') for a in anchors]\n",
    "        #narrow down all links to image links only\n",
    "    anchors = [a for a in anchors if str(a).startswith(\"https://www.facebook.com/page/photos/\")]\n",
    "\n",
    "    for a in anchors:\n",
    "        driver.get(a) \n",
    "        time.sleep(5) \n",
    "        img = driver.find_elements_by_tag_name(\"img\") # list of links\n",
    "        images.append(img[0].get_attribute(\"src\")) # the photo link is the first element within the list, but it can change\n",
    "\n",
    "print('The total amount of found links'+ str(len(images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Downloading the images\n",
    "\n",
    "The final step is the images download.\n",
    "\n",
    "- Set the path to store the images\n",
    "- A loop over the images list\n",
    "- Download the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(path) # Making a folder in the currently directory, it's optional.\n",
    "path = os.getcwd() # Getting the currently directory\n",
    "path = os.path.join(path, \"scraped_imgs\") # Path to store the images\n",
    "\n",
    "counter = 1\n",
    "for image in images:\n",
    "    save_as = os.path.join(path, 'photo.' + str(counter) + '.jpg') # setting the path\n",
    "    wget.download(image, save_as) # downloading the images\n",
    "    count += 1 # increase the counter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
